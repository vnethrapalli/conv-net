{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- expected input volume to be an array of 3d images\n",
    "- filters is a list of 3d array filters\n",
    "- biases is a list of bias terms, one for each filter\n",
    "'''\n",
    "def convolution(input_volume, filters, biases, stride=1, zero_padding=0):\n",
    "    \n",
    "    # assume square images\n",
    "    num_images, num_channels, _, img_dim_orig = input_volume.shape\n",
    "    num_filters, _, __, filter_dim = filters.shape\n",
    "    \n",
    "    \n",
    "    # zero padding adds zeroes around the input, but not along the depth dimension of each image\n",
    "    image = input_volume\n",
    "    if zero_padding != 0:\n",
    "        image = np.zeros(shape=(num_images, num_channels, img_dim_orig + 2 * zero_padding, img_dim_orig + 2 * zero_padding))\n",
    "        image[:, :, zero_padding:-zero_padding, zero_padding:-zero_padding] = input_volume\n",
    "    \n",
    "    img_dim = img_dim_orig + 2 * zero_padding\n",
    "    \n",
    "    \n",
    "    # im2col 3d from:\n",
    "    # https://stackoverflow.com/questions/50292750/python-the-implementation-of-im2col-which-takes-the-advantages-of-6-dimensional\n",
    "    img_stride, channel_stride, row_stride, col_stride = image.strides\n",
    "    out_dim = (img_dim - filter_dim) // stride + 1\n",
    "    col = np.lib.stride_tricks.as_strided(image, shape=(num_images, out_dim, out_dim, num_channels, filter_dim, filter_dim), strides=(img_stride, stride * row_stride, stride * col_stride, channel_stride, row_stride, col_stride)).astype(float)\n",
    "    col = col.reshape(np.multiply.reduceat(col.shape, (0, 3)))\n",
    "    \n",
    "    # each 2d slice of col has rows containing each extended receptive field\n",
    "    # similarly, the filters will be flattened into a 2d array (col: each filter stretched out)\n",
    "    filt_stride, filt_depth_stride, filt_row_stride, filt_col_stride = filters.strides\n",
    "    filt_col = np.lib.stride_tricks.as_strided(filters, shape=(num_channels * filter_dim ** 2, num_filters), strides=(filt_col_stride, filt_stride))\n",
    "    \n",
    "    # perform matrix multiplication\n",
    "    # each col is a different filter; every out_dim^2 rows corresponds to one image's convolved activations\n",
    "    conv = np.dot(col, filt_col)\n",
    "    conv_row_stride, conv_col_stride = conv.strides\n",
    "    \n",
    "    # add bias term (each filter should have one)\n",
    "    conv += biases\n",
    "    \n",
    "    # reshape into list of activation volumes (1 volume per image)\n",
    "    conv = np.lib.stride_tricks.as_strided(conv, shape=(num_images, num_filters, out_dim, out_dim), strides=(out_dim ** 2 * conv_row_stride, conv_col_stride, out_dim * conv_row_stride, conv_row_stride))\n",
    "\n",
    "    return conv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  7., 11.],\n",
       "         [ 2.,  9., -3.],\n",
       "         [ 3., -5.,  3.]],\n",
       "\n",
       "        [[ 0., -5., -1.],\n",
       "         [-9.,  1.,  3.],\n",
       "         [-3., -1., -1.]]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test convolution from https://cs231n.github.io/convolutional-networks/\n",
    "img = np.asarray([0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 2, 0, 1, 1, 2,\n",
    "                 0, 0, 0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
    "                 1, 0, 0, 2, 1, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2])\n",
    "img = img.reshape((1, 3, 5, 5))\n",
    "\n",
    "w0 = np.asarray([-1, 0, 1, 1, 1, -1, 0, 1, 0,\n",
    "                -1, -1, 1, -1, 1, -1, 1, 0, 1,\n",
    "                0, -1, -1, 1, -1, 1, 1, 1, 1])\n",
    "w0 = w0.reshape((3, 3, 3))\n",
    "\n",
    "w1 = np.asarray([-1, 1, 1, 0, -1, 0, 0, 0, -1,\n",
    "                1, 0, 0, -1, -1, -1, 0, -1, 0,\n",
    "                0, -1, -1, 1, 1, -1, 1, 1, 0])\n",
    "w1 = w1.reshape((3, 3, 3))\n",
    "\n",
    "filters = np.asarray([w0, w1]).reshape((2, 3, 3, 3))\n",
    "biases = np.asarray([1, 0])\n",
    "\n",
    "convolution(img, filters, biases, stride=2, zero_padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- expected input volume to be an array of 3d images\n",
    "- filters is a list of 3d array filters\n",
    "- biases is a list of bias terms, one for each filter\n",
    "- maintain_depth: convolve channel by channel instead of one volume becoming a single depth slice\n",
    "--> if true, does not use bias, since it should not be applied to each depth slice\n",
    "'''\n",
    "def convolution(input_volume, filters, biases, stride=1, zero_padding=0, maintain_depth=False):\n",
    "    \n",
    "    # assume square images\n",
    "    num_images, num_channels, _, img_dim_orig = input_volume.shape\n",
    "    num_filters, _, __, filter_dim = filters.shape\n",
    "    \n",
    "    \n",
    "    # zero padding adds zeroes around the input, but not along the depth dimension of each image\n",
    "    image = input_volume\n",
    "    if zero_padding != 0:\n",
    "        image = np.zeros(shape=(num_images, num_channels, img_dim_orig + 2 * zero_padding, img_dim_orig + 2 * zero_padding))\n",
    "        image[:, :, zero_padding:-zero_padding, zero_padding:-zero_padding] = input_volume\n",
    "    \n",
    "    img_dim = img_dim_orig + 2 * zero_padding\n",
    "    \n",
    "    \n",
    "    # im2col 3d from:\n",
    "    # https://stackoverflow.com/questions/50292750/python-the-implementation-of-im2col-which-takes-the-advantages-of-6-dimensional\n",
    "    img_stride, channel_stride, row_stride, col_stride = image.strides\n",
    "    out_dim = (img_dim - filter_dim) // stride + 1\n",
    "    col = np.lib.stride_tricks.as_strided(image, shape=(num_images, out_dim, out_dim, num_channels, filter_dim, filter_dim), strides=(img_stride, stride * row_stride, stride * col_stride, channel_stride, row_stride, col_stride)).astype(float)\n",
    "    \n",
    "    if maintain_depth:\n",
    "        col = col.reshape((num_images * out_dim ** 2 * num_channels, filter_dim ** 2))\n",
    "    else:\n",
    "        col = col.reshape(np.multiply.reduceat(col.shape, (0, 3)))\n",
    "    \n",
    "    # each 2d slice of col has rows containing each extended receptive field\n",
    "    # similarly, the filters will be flattened into a 2d array (col: each filter stretched out)\n",
    "    filt_stride, filt_depth_stride, filt_row_stride, filt_col_stride = filters.strides\n",
    "                        \n",
    "    filt_col = None\n",
    "    if (maintain_depth):\n",
    "        filt_col = np.lib.stride_tricks.as_strided(filters, \n",
    "                                                   shape=(filter_dim ** 2, num_channels * num_filters), \n",
    "                                                   strides=(filt_col_stride, filt_depth_stride))\n",
    "    else:\n",
    "        filt_col = np.lib.stride_tricks.as_strided(filters, \n",
    "                                                   shape=(num_channels * filter_dim ** 2, num_filters), \n",
    "                                                   strides=(filt_col_stride, filt_stride))\n",
    "                              \n",
    "    # perform matrix multiplication\n",
    "    # each col is a different filter; every out_dim^2 rows corresponds to one image's convolved activations\n",
    "    conv = np.dot(col, filt_col)\n",
    "                          \n",
    "    if maintain_depth:\n",
    "        # conv contains convolutions of depth slices with other slices, so the correct ones must be extracted\n",
    "        # has #columns = num_filters * num_channels\n",
    "        # up to num_channel th column, shift 1st column up 0, 2nd up 1, 3rd up 2; then repeat for each filter's columns\n",
    "        # then take every num_channel th row\n",
    "        rows, cols = conv.shape\n",
    "        for col in range(cols):\n",
    "            shift = col % num_channels\n",
    "            if shift != 0:\n",
    "                conv[:-shift, [col]] = conv[shift:, [col]]\n",
    "            \n",
    "        conv = conv[np.arange(0, rows, step=num_channels), :]\n",
    "        \n",
    "        # reshape into a 5d array of outputs\n",
    "        # 5th dim contains the result for each image \n",
    "        # 4th dimension contains convolutions maintaining depth, for each filter\n",
    "        # 3rd, 2nd, 1st dimensions are the outputs with the depths maintained\n",
    "        conv_row_stride, conv_col_stride = conv.strides\n",
    "        conv = np.lib.stride_tricks.as_strided(conv, \n",
    "                                               shape=(num_images, num_filters, num_channels, out_dim, out_dim),\n",
    "                                               strides=(out_dim ** 2 * conv_row_stride, num_channels * conv_col_stride, conv_col_stride, out_dim * conv_row_stride, conv_row_stride))\n",
    "        \n",
    "    else:\n",
    "        # add bias term (each filter should have one)\n",
    "        conv += biases\n",
    "    \n",
    "        # reshape into list of activation volumes (1 volume per image)\n",
    "        conv_row_stride, conv_col_stride = conv.strides\n",
    "        conv = np.lib.stride_tricks.as_strided(conv, shape=(num_images, num_filters, out_dim, out_dim), strides=(out_dim ** 2 * conv_row_stride, conv_col_stride, out_dim * conv_row_stride, conv_row_stride))\n",
    "\n",
    "    return conv\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  7., 11.],\n",
       "         [ 2.,  9., -3.],\n",
       "         [ 3., -5.,  3.]],\n",
       "\n",
       "        [[ 0., -5., -1.],\n",
       "         [-9.,  1.,  3.],\n",
       "         [-3., -1., -1.]]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test convolution from https://cs231n.github.io/convolutional-networks/\n",
    "img = np.asarray([0, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 1, 0, 2, 0, 1, 1, 2,\n",
    "                 0, 0, 0, 2, 1, 2, 0, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
    "                 1, 0, 0, 2, 1, 2, 1, 1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2])\n",
    "img = img.reshape((1, 3, 5, 5))\n",
    "\n",
    "w0 = np.asarray([-1, 0, 1, 1, 1, -1, 0, 1, 0,\n",
    "                -1, -1, 1, -1, 1, -1, 1, 0, 1,\n",
    "                0, -1, -1, 1, -1, 1, 1, 1, 1])\n",
    "w0 = w0.reshape((3, 3, 3))\n",
    "\n",
    "w1 = np.asarray([-1, 1, 1, 0, -1, 0, 0, 0, -1,\n",
    "                1, 0, 0, -1, -1, -1, 0, -1, 0,\n",
    "                0, -1, -1, 1, 1, -1, 1, 1, 0])\n",
    "w1 = w1.reshape((3, 3, 3))\n",
    "\n",
    "filters = np.asarray([w0, w1]).reshape((2, 3, 3, 3))\n",
    "biases = np.asarray([1, 0])\n",
    "\n",
    "convolution(img, filters, biases, stride=2, zero_padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.,  7., 11.],\n",
       "         [ 2.,  9., -3.],\n",
       "         [ 3., -5.,  3.]],\n",
       "\n",
       "        [[ 1., -4.,  0.],\n",
       "         [-8.,  2.,  4.],\n",
       "         [-2.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for convolution maintaining the depth\n",
    "z = convolution(img, filters, biases, stride=2, zero_padding=1, maintain_depth=True)\n",
    "z = np.sum(z, axis=2)\n",
    "for i, l in enumerate(z):\n",
    "    l += biases[i]\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- expected input volume to be an array of 3d images\n",
    "- (square) sliding window dimensions\n",
    "- modes: max pooling, min pooling, mean pooling\n",
    "- stride: for sliding viewing window\n",
    "- zero_padding: zero padding\n",
    "'''\n",
    "def pool(input_volumes, filter_dim, mode='max', stride=1, zero_padding=0): \n",
    "    # assume square images\n",
    "    num_images, num_channels, _, img_dim_orig = input_volumes.shape   \n",
    "    \n",
    "    # zero padding adds zeroes around the input, but not along the depth dimension of each image\n",
    "    image = input_volumes\n",
    "    if zero_padding != 0:\n",
    "        image = np.zeros(shape=(num_images, num_channels, img_dim_orig + 2 * zero_padding, img_dim_orig + 2 * zero_padding))\n",
    "        image[:, :, zero_padding:-zero_padding, zero_padding:-zero_padding] = input_volume\n",
    "    \n",
    "    img_dim = img_dim_orig + 2 * zero_padding\n",
    "    \n",
    "    # im2col 3d from:\n",
    "    # https://stackoverflow.com/questions/50292750/python-the-implementation-of-im2col-which-takes-the-advantages-of-6-dimensional\n",
    "    img_stride, channel_stride, row_stride, col_stride = image.strides\n",
    "    out_dim = (img_dim - filter_dim) // stride + 1\n",
    "    col = np.lib.stride_tricks.as_strided(image, shape=(num_images, out_dim, out_dim, num_channels, filter_dim, filter_dim), strides=(img_stride, stride * row_stride, stride * col_stride, channel_stride, row_stride, col_stride)).astype(float)\n",
    "    # col = col.reshape(np.multiply.reduceat(col.shape, (0, 3)))\n",
    "    col = col.reshape((num_images, num_channels * out_dim ** 2, filter_dim ** 2))\n",
    "    \n",
    "    # perform the pooling operations\n",
    "    result = None\n",
    "    if mode == 'max':\n",
    "        result = col.max(axis=2)\n",
    "    elif mode == 'min':\n",
    "        result = col.min(axis=2)\n",
    "    elif mode == 'mean':\n",
    "        result = col.mean(axis=2)\n",
    "        \n",
    "    # reshape result into list of images\n",
    "    row_stride, col_stride = result.strides\n",
    "    result = np.lib.stride_tricks.as_strided(result, shape=(num_images, num_channels, out_dim, out_dim), strides=(row_stride, col_stride, num_channels * out_dim * col_stride, num_channels * col_stride))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pooling testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:\n",
      "[[[[2 2 3 3 0]\n",
      "   [1 4 4 4 0]\n",
      "   [2 4 0 3 2]\n",
      "   [4 4 3 1 4]\n",
      "   [2 3 4 1 3]]\n",
      "\n",
      "  [[4 0 2 0 2]\n",
      "   [0 3 1 1 1]\n",
      "   [0 1 0 2 0]\n",
      "   [0 1 0 2 2]\n",
      "   [4 2 3 1 1]]\n",
      "\n",
      "  [[0 3 4 3 4]\n",
      "   [3 3 4 4 0]\n",
      "   [3 1 3 2 1]\n",
      "   [3 1 1 1 3]\n",
      "   [4 3 3 4 2]]]]\n",
      "\n",
      "max pooling:\n",
      "[[[[4. 4.]\n",
      "   [4. 4.]]\n",
      "\n",
      "  [[4. 2.]\n",
      "   [4. 3.]]\n",
      "\n",
      "  [[4. 4.]\n",
      "   [4. 4.]]]]\n",
      "\n",
      "min pooling:\n",
      "[[[[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [0. 0.]]\n",
      "\n",
      "  [[0. 0.]\n",
      "   [1. 1.]]]]\n",
      "\n",
      "mean pooling:\n",
      "[[[[2.44444444 2.11111111]\n",
      "   [2.88888889 2.33333333]]\n",
      "\n",
      "  [[1.22222222 1.        ]\n",
      "   [1.22222222 1.22222222]]\n",
      "\n",
      "  [[2.66666667 2.77777778]\n",
      "   [2.44444444 2.22222222]]]]\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randint(0, 5, size=75).reshape((1, 3, 5, 5))\n",
    "print(f'image:\\n{img}')\n",
    "\n",
    "print(f'\\nmax pooling:\\n{pool(img, 3, mode=\"max\", stride=2)}\\n')\n",
    "print(f'min pooling:\\n{pool(img, 3, mode=\"min\", stride=2)}\\n')\n",
    "print(f'mean pooling:\\n{pool(img, 3, mode=\"mean\", stride=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

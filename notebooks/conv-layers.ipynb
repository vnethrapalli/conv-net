{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolution and pooling operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- expected input volume to be an array of 3d images\n",
    "- filters is a list of 3d array filters\n",
    "- biases is a list of bias terms, one for each filter\n",
    "- maintain_depth: convolve channel by channel instead of one volume becoming a single depth slice\n",
    "--> if true, does not use bias, since it should not be applied to each depth slice\n",
    "'''\n",
    "def convolution(input_volume, filters, biases, stride=1, zero_padding=0, maintain_depth=False):\n",
    "    \n",
    "    # assume square images\n",
    "    num_images, num_channels, _, img_dim_orig = input_volume.shape\n",
    "    num_filters, _, __, filter_dim = filters.shape\n",
    "    \n",
    "    \n",
    "    # zero padding adds zeroes around the input, but not along the depth dimension of each image\n",
    "    image = input_volume\n",
    "    if zero_padding != 0:\n",
    "        image = np.zeros(shape=(num_images, num_channels, img_dim_orig + 2 * zero_padding, img_dim_orig + 2 * zero_padding))\n",
    "        image[:, :, zero_padding:-zero_padding, zero_padding:-zero_padding] = input_volume\n",
    "    \n",
    "    img_dim = img_dim_orig + 2 * zero_padding\n",
    "    \n",
    "    \n",
    "    # im2col 3d from:\n",
    "    # https://stackoverflow.com/questions/50292750/python-the-implementation-of-im2col-which-takes-the-advantages-of-6-dimensional\n",
    "    img_stride, channel_stride, row_stride, col_stride = image.strides\n",
    "    out_dim = (img_dim - filter_dim) // stride + 1\n",
    "    col = np.lib.stride_tricks.as_strided(image, shape=(num_images, out_dim, out_dim, num_channels, filter_dim, filter_dim), strides=(img_stride, stride * row_stride, stride * col_stride, channel_stride, row_stride, col_stride)).astype(float)\n",
    "    \n",
    "    if maintain_depth:\n",
    "        col = col.reshape((num_images * out_dim ** 2 * num_channels, filter_dim ** 2))\n",
    "    else:\n",
    "        col = col.reshape(np.multiply.reduceat(col.shape, (0, 3)))\n",
    "    \n",
    "    # each 2d slice of col has rows containing each extended receptive field\n",
    "    # similarly, the filters will be flattened into a 2d array (col: each filter stretched out)\n",
    "    filt_stride, filt_depth_stride, filt_row_stride, filt_col_stride = filters.strides\n",
    "                        \n",
    "    filt_col = None\n",
    "    if (maintain_depth):\n",
    "        filt_col = np.lib.stride_tricks.as_strided(filters, \n",
    "                                                   shape=(filter_dim ** 2, num_channels * num_filters), \n",
    "                                                   strides=(filt_col_stride, filt_depth_stride))\n",
    "    else:\n",
    "        filt_col = np.lib.stride_tricks.as_strided(filters, \n",
    "                                                   shape=(num_channels * filter_dim ** 2, num_filters), \n",
    "                                                   strides=(filt_col_stride, filt_stride))\n",
    "                              \n",
    "    # perform matrix multiplication\n",
    "    # each col is a different filter; every out_dim^2 rows corresponds to one image's convolved activations\n",
    "    conv = np.dot(col, filt_col)\n",
    "                          \n",
    "    if maintain_depth:\n",
    "        # conv contains convolutions of depth slices with other slices, so the correct ones must be extracted\n",
    "        # has #columns = num_filters * num_channels\n",
    "        # up to num_channel th column, shift 1st column up 0, 2nd up 1, 3rd up 2; then repeat for each filter's columns\n",
    "        # then take every num_channel th row\n",
    "        rows, cols = conv.shape\n",
    "        for col in range(cols):\n",
    "            shift = col % num_channels\n",
    "            if shift != 0:\n",
    "                conv[:-shift, [col]] = conv[shift:, [col]]\n",
    "            \n",
    "        conv = conv[np.arange(0, rows, step=num_channels), :]\n",
    "        \n",
    "        # reshape into a 5d array of outputs\n",
    "        # 5th dim contains the result for each image \n",
    "        # 4th dimension contains convolutions maintaining depth, for each filter\n",
    "        # 3rd, 2nd, 1st dimensions are the outputs with the depths maintained\n",
    "        conv_row_stride, conv_col_stride = conv.strides\n",
    "        conv = np.lib.stride_tricks.as_strided(conv, \n",
    "                                               shape=(num_images, num_filters, num_channels, out_dim, out_dim),\n",
    "                                               strides=(out_dim ** 2 * conv_row_stride, num_channels * conv_col_stride, conv_col_stride, out_dim * conv_row_stride, conv_row_stride))\n",
    "        \n",
    "    else:\n",
    "        # add bias term (each filter should have one)\n",
    "        conv += biases\n",
    "    \n",
    "        # reshape into list of activation volumes (1 volume per image)\n",
    "        conv_row_stride, conv_col_stride = conv.strides\n",
    "        conv = np.lib.stride_tricks.as_strided(conv, shape=(num_images, num_filters, out_dim, out_dim), strides=(out_dim ** 2 * conv_row_stride, conv_col_stride, out_dim * conv_row_stride, conv_row_stride))\n",
    "\n",
    "    return conv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- expected input volume to be an array of 3d images\n",
    "- (square) sliding window dimensions\n",
    "- modes: max pooling, min pooling, mean pooling\n",
    "- stride: for sliding viewing window\n",
    "- zero_padding: zero padding\n",
    "'''\n",
    "def pool(input_volumes, filter_dim, mode='max', stride=1, zero_padding=0): \n",
    "    # assume square images\n",
    "    num_images, num_channels, _, img_dim_orig = input_volumes.shape   \n",
    "    \n",
    "    # zero padding adds zeroes around the input, but not along the depth dimension of each image\n",
    "    image = input_volumes\n",
    "    if zero_padding != 0:\n",
    "        image = np.zeros(shape=(num_images, num_channels, img_dim_orig + 2 * zero_padding, img_dim_orig + 2 * zero_padding))\n",
    "        image[:, :, zero_padding:-zero_padding, zero_padding:-zero_padding] = input_volume\n",
    "    \n",
    "    img_dim = img_dim_orig + 2 * zero_padding\n",
    "    \n",
    "    # im2col 3d from:\n",
    "    # https://stackoverflow.com/questions/50292750/python-the-implementation-of-im2col-which-takes-the-advantages-of-6-dimensional\n",
    "    img_stride, channel_stride, row_stride, col_stride = image.strides\n",
    "    out_dim = (img_dim - filter_dim) // stride + 1\n",
    "    col = np.lib.stride_tricks.as_strided(image, shape=(num_images, out_dim, out_dim, num_channels, filter_dim, filter_dim), strides=(img_stride, stride * row_stride, stride * col_stride, channel_stride, row_stride, col_stride)).astype(float)\n",
    "    # col = col.reshape((num_images, num_channels * out_dim ** 2, filter_dim ** 2))\n",
    "    col = col.reshape((num_images * num_channels * out_dim ** 2, filter_dim ** 2))\n",
    "    \n",
    "    # store the indices of max or min values for use in backpropagation \n",
    "    # in col receptive areas rolled out horizontally, with each depth in a different row, and then each image's rows stacked\n",
    "    mask_idx = None\n",
    "    if mode == 'max':\n",
    "        mask_idx = np.argmax(col, axis=1)\n",
    "    elif mode == 'min':\n",
    "        mask_idx= np.argmin(col, axis=1)\n",
    "    \n",
    "    # perform the pooling operations\n",
    "    result = None\n",
    "    if mode == 'max':\n",
    "        result = col.max(axis=1)\n",
    "    elif mode == 'min':\n",
    "        result = col.min(axis=1)\n",
    "    elif mode == 'mean':\n",
    "        result = col.mean(axis=1)\n",
    "        \n",
    "    # reshape result into list of images\n",
    "    data_stride = result.strides[0]\n",
    "    result = np.lib.stride_tricks.as_strided(result, \n",
    "                                             shape=(num_images, num_channels, out_dim, out_dim), \n",
    "                                             strides=(out_dim ** 2 * num_channels * data_stride, data_stride, num_channels * out_dim * data_stride, num_channels * data_stride))\n",
    "    if mode == 'min' or mode == 'max':\n",
    "        return result, mask_idx\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer class to group information about layers\n",
    "class Layer:\n",
    "    '''\n",
    "    layer_type: 'conv' or 'pool'\n",
    "    filters_shape: shape tuple if layer_type is 'conv' (expected 4D); single dimension for square window if layer_type is 'pool'\n",
    "    stride, zero_padding: constants representing the stride and amount of zeroes added to the border of an input\n",
    "    pooling_mode: method used in pooling: 'max', 'min', or 'mean'\n",
    "    '''\n",
    "    def __init__(self, layer_type, filters_shape, stride=1, zero_padding=0, pooling_mode='max'):\n",
    "        self.layer_type = layer_type\n",
    "        \n",
    "        # initialize filter weights\n",
    "        self.filters = None\n",
    "        self.filter_dim = None\n",
    "        \n",
    "        if layer_type == 'conv':\n",
    "            self.filters = np.random.normal(size=filters_shape)\n",
    "            self.biases = np.random.normal(size=self.filters.shape[0])\n",
    "        elif layer_type == 'pool':\n",
    "            self.filter_dim = filters_shape\n",
    "            \n",
    "        self.stride = stride\n",
    "        self.zero_padding = zero_padding\n",
    "        self.pooling_mode = pooling_mode\n",
    "        \n",
    "    def __str__(self):\n",
    "        if self.layer_type == 'conv':\n",
    "            return f'conv(filters_shape=({self.filters.shape}), stride={self.stride}, zero_padding={self.zero_padding})'\n",
    "            \n",
    "        elif self.layer_type == 'pool':\n",
    "            return f'pool(filter_dim={self.filter_dim}, stride={self.stride}, zero_padding={self.zero_padding}, pooling_mode={self.pooling_mode})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv(filters_shape=((4, 1, 3, 3)), stride=1, zero_padding=1)\n",
      "conv(filters_shape=((3, 4, 3, 3)), stride=1, zero_padding=0)\n",
      "pool(filter_dim=2, stride=2, zero_padding=0, pooling_mode=max)\n"
     ]
    }
   ],
   "source": [
    "# makeshift way of specifying structure of the layers\n",
    "# separate layers with a pipe: |\n",
    "# start each layer with the type of layer and a semi colon: ie conv; or pool;\n",
    "# no spaces?\n",
    "# separate parameters with a semicolon: ;\n",
    "# conv params: filter f=shape tuple; stride s=num; zero padding z=num\n",
    "# - note that the depth of the shape will be overridden by the previous layer's depth, since the filter extends through the input volume\n",
    "# pooling params: filter dimension fdim=num; mode m='max' (or mean or min); stride s=num, zero padding z=num\n",
    "\n",
    "structure_str = 'conv;f=4,1,3,3;s=1;z=1|conv;f=3,1,3,3;s=1;z=0|pool;fdim=2;m=max;s=2;z=0'\n",
    "imgs = np.arange(108).reshape((3, 1, 6, 6))\n",
    "prev_layer_depth = imgs.shape[1]\n",
    "\n",
    "layers = np.asarray([])\n",
    "for layer_str in structure_str.split('|'):\n",
    "    param_str = layer_str.split(';')\n",
    "    layer_type = param_str[0]\n",
    "    \n",
    "    # read in expected params for conv\n",
    "    if layer_type == 'conv':\n",
    "        shape = stride = padding = None\n",
    "        \n",
    "        for param in param_str[1:]:\n",
    "            p, value = param.split('=')\n",
    "            if p == 'f':\n",
    "                shape = [int(v) for v in value.split(',')]\n",
    "                # the depth of the filter is equal to the depth of the input volume; the depth of the lext layer will equal number of filters\n",
    "                shape[1] = prev_layer_depth\n",
    "                prev_layer_depth = shape[0] \n",
    "            elif p == 's':\n",
    "                stride = int(value)\n",
    "            elif p == 'z':\n",
    "                padding = int(value)\n",
    "                \n",
    "        layers = np.append(layers, Layer('conv', shape, stride, padding, pooling_mode=None))\n",
    "                \n",
    "    # read in expected params for pool\n",
    "    elif layer_type == 'pool':\n",
    "        window_dim = stride = padding = pooling_method = None\n",
    "        \n",
    "        for param in param_str[1:]:\n",
    "            p, value = param.split('=')\n",
    "            if p == 'fdim':\n",
    "                window_dim = int(value)\n",
    "            elif p == 's':\n",
    "                stride = int(value)\n",
    "            elif p == 'z':\n",
    "                padding = int(value)\n",
    "            elif p == 'm':\n",
    "                pooling_method = value\n",
    "                \n",
    "        layers = np.append(layers, Layer('pool', window_dim, stride, padding, pooling_method))\n",
    "        \n",
    "for l in layers:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 20.97333621, 118.94082573],\n",
       "         [133.63921631, 182.54240548]],\n",
       "\n",
       "        [[145.67059479, 128.08008664],\n",
       "         [114.21088904,  94.25781463]],\n",
       "\n",
       "        [[  0.        ,   0.        ],\n",
       "         [  0.        ,   0.        ]]],\n",
       "\n",
       "\n",
       "       [[[221.66616401, 484.97551843],\n",
       "         [393.29542472, 545.98130055]],\n",
       "\n",
       "        [[222.50004556, 155.54086702],\n",
       "         [ 28.72348642,  26.85107705]],\n",
       "\n",
       "        [[  0.        ,   0.        ],\n",
       "         [  0.        ,   0.        ]]],\n",
       "\n",
       "\n",
       "       [[[431.38368445, 851.01021113],\n",
       "         [652.95163312, 912.01599325]],\n",
       "\n",
       "        [[304.26338517, 192.07550155],\n",
       "         [  0.        ,   0.        ]],\n",
       "\n",
       "        [[  0.        ,   0.        ],\n",
       "         [  0.        ,   0.        ]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv_fprop(imgs, layers):\n",
    "    output = imgs.copy()\n",
    "    activation_volumes = [output]\n",
    "    for l in layers:\n",
    "        if l.layer_type =='conv':\n",
    "            output = convolution(output, l.filters, l.biases, l.stride, l.zero_padding)\n",
    "\n",
    "            # i think this goes before the activation function, for use in backprop\n",
    "            activation_volumes.append(output)\n",
    "            # todo activation function\n",
    "            \n",
    "            # ie ReLU\n",
    "            output[output < 0] = 0 \n",
    "            \n",
    "            \n",
    "        elif l.layer_type == 'pool':\n",
    "            output = pool(output, l.filter_dim, mode=l.pooling_mode, stride=l.stride, zero_padding=l.zero_padding)\n",
    "            activation_volumes.append(output)\n",
    "            \n",
    "    return activation_volumes\n",
    "        \n",
    "# note that the first element contains the input images\n",
    "activations = conv_fprop(imgs, layers) \n",
    "print(activations[-1].shape)\n",
    "activations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6d15ce88bb9d>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-6d15ce88bb9d>\"\u001b[1;36m, line \u001b[1;32m30\u001b[0m\n\u001b[1;33m    err[]\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# adjust layer weights and biases\n",
    "learning_rate = 0.1\n",
    "def conv_bprop_gradient(layers, incoming_errors, activations):\n",
    "    # https://towardsdatascience.com/backpropagation-in-a-convolutional-layer-24c8d64d8509\n",
    "    # https://medium.com/@mayank.utexas/backpropagation-for-convolution-with-strides-8137e4fc2710\n",
    "    \n",
    "    curr_error = incoming_errors\n",
    "    bias_grad = filter_grad = next_errors = None\n",
    "    \n",
    "    # todo account for activation function\n",
    "    \n",
    "    for l, activation in reversed(zip(layers, activations[:-1])):\n",
    "        if l.layer_type == 'conv':\n",
    "            # **bias gradient** for each filter is the sum of the errors for that filter (across all images)\n",
    "            bias_grad = np.sum(curr_error, axis=(0, 2, 3))\n",
    "            \n",
    "            # incoming error depth slices are associated with each filter and each depth slice of the image... so each slice \n",
    "            # will be stacked to match the depth of the image, and then used as a \"filter\" since the gradient can be computed\n",
    "            # using a convolution\n",
    "            num_images, num_filters, rows, cols = curr_error.shape\n",
    "            new_dim = cols + (cols - 1) * (l.stride - 1)\n",
    "            \n",
    "            # **weight and input gradients**\n",
    "            \n",
    "            # add stride - 1 zeroes between error elements so that the convolutions work out\n",
    "            strided_error = curr_error\n",
    "            if l.stride > 1:\n",
    "                # array with new dimensions (same number of rows and cols)\n",
    "                err = np.zeros(shape=(num_images, num_filters, new_dim, new_dim))\n",
    "\n",
    "                for i in range(rows):\n",
    "                    for j in range(cols):\n",
    "                        err[:, :, [i * l.stride], [j * l.stride]] = curr_error[:, :, [i], [j]]\n",
    "\n",
    "                strided_error = err\n",
    "            \n",
    "        \n",
    "            # 5d array: first 3 dims are filter, 4th dim is each image's incoming error, 5th dim is each \"stacked\" slice\n",
    "            image_stride, channel_stride, row_stride, col_stride = strided_error.strides\n",
    "            depth = l.weights.shape[1]\n",
    "            strided_error = np.lib.stride_tricks.as_strided(strided_error,\n",
    "                                                            shape=(num_filters, num_images, depth, new_dim, new_dim), \n",
    "                                                            strides=(channel_stride, image_stride, 0, row_stride, col_stride))\n",
    "            \n",
    "            \n",
    "            # calculate the next layer's error:\n",
    "            new_shape = strided_error.shape\n",
    "            padding = l.filters[0].shape[-1] - 1\n",
    "            \n",
    "            input_grad = np.zeros(shape=activation.shape)\n",
    "            for f in range(len(l.filters)):\n",
    "                w = np.rot90(l.filters[f], 2, axes=(1, 2))\n",
    "                w = np.asarray([w])\n",
    "                dx = convolution(strided_error[f], w, None, stride=1, zero_padding=padding, maintain_depth=True)\n",
    "                input_grad += dx[:, 0, :, :, :]\n",
    "            \n",
    "\n",
    "            # calculate the weight gradient\n",
    "            \n",
    "            # each incoming error is associated with one image only, and so that error should only \n",
    "            # be convolved with its respective image\n",
    "            weight_error = np.zeros(l.filters.shape)\n",
    "\n",
    "            # iterate through images.. might be slow :(\n",
    "            for i in range(len(num_images)):\n",
    "                dw = convolution(activation, strided_error[:, i, :, :, :], biases=None, stride=1, zero_padding=0, maintain_depth=True)\n",
    "                weight_error += dw\n",
    "                \n",
    "            # todo update the weights and biases using the calculated gradient\n",
    "            l.biases -= learning_rate * bias_grad\n",
    "            l.filters -= learning_rate * weight_error\n",
    "        \n",
    "            curr_error = input_grad\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[-2.10889924e-001,  0.00000000e+000, -4.81065959e-001,\n",
       "            0.00000000e+000, -4.43586104e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.47904212e+000,  0.00000000e+000, -2.53627079e-001,\n",
       "            0.00000000e+000,  1.53193938e+000],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.64205935e+000,  0.00000000e+000, -1.44471887e+000,\n",
       "            0.00000000e+000,  6.55718226e-001]],\n",
       "\n",
       "         [[-2.10889924e-001,  0.00000000e+000, -4.81065959e-001,\n",
       "            0.00000000e+000, -4.43586104e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.47904212e+000,  0.00000000e+000, -2.53627079e-001,\n",
       "            0.00000000e+000,  1.53193938e+000],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.64205935e+000,  0.00000000e+000, -1.44471887e+000,\n",
       "            0.00000000e+000,  6.55718226e-001]],\n",
       "\n",
       "         [[-2.10889924e-001,  0.00000000e+000, -4.81065959e-001,\n",
       "            0.00000000e+000, -4.43586104e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.47904212e+000,  0.00000000e+000, -2.53627079e-001,\n",
       "            0.00000000e+000,  1.53193938e+000],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.64205935e+000,  0.00000000e+000, -1.44471887e+000,\n",
       "            0.00000000e+000,  6.55718226e-001]]],\n",
       "\n",
       "\n",
       "        [[[-9.45994353e-001,  0.00000000e+000, -5.44660466e-001,\n",
       "            0.00000000e+000, -3.65070111e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.34193343e+000,  0.00000000e+000,  8.08511693e-001,\n",
       "            0.00000000e+000,  4.68190004e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.74775654e-001,  0.00000000e+000,  3.49389156e-002,\n",
       "            0.00000000e+000,  2.27314864e-001]],\n",
       "\n",
       "         [[-9.45994353e-001,  0.00000000e+000, -5.44660466e-001,\n",
       "            0.00000000e+000, -3.65070111e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.34193343e+000,  0.00000000e+000,  8.08511693e-001,\n",
       "            0.00000000e+000,  4.68190004e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.74775654e-001,  0.00000000e+000,  3.49389156e-002,\n",
       "            0.00000000e+000,  2.27314864e-001]],\n",
       "\n",
       "         [[-9.45994353e-001,  0.00000000e+000, -5.44660466e-001,\n",
       "            0.00000000e+000, -3.65070111e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.34193343e+000,  0.00000000e+000,  8.08511693e-001,\n",
       "            0.00000000e+000,  4.68190004e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.74775654e-001,  0.00000000e+000,  3.49389156e-002,\n",
       "            0.00000000e+000,  2.27314864e-001]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[ 2.96399854e-001,  0.00000000e+000,  7.39092249e-001,\n",
       "            0.00000000e+000, -5.63398088e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-3.99876498e-001,  0.00000000e+000, -2.04645311e-001,\n",
       "            0.00000000e+000,  6.05273523e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 7.21389319e-001,  0.00000000e+000,  8.32389858e-001,\n",
       "            0.00000000e+000, -7.01374686e-001]],\n",
       "\n",
       "         [[ 2.96399854e-001,  0.00000000e+000,  7.39092249e-001,\n",
       "            0.00000000e+000, -5.63398088e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-3.99876498e-001,  0.00000000e+000, -2.04645311e-001,\n",
       "            0.00000000e+000,  6.05273523e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 7.21389319e-001,  0.00000000e+000,  8.32389858e-001,\n",
       "            0.00000000e+000, -7.01374686e-001]],\n",
       "\n",
       "         [[ 2.96399854e-001,  0.00000000e+000,  7.39092249e-001,\n",
       "            0.00000000e+000, -5.63398088e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-3.99876498e-001,  0.00000000e+000, -2.04645311e-001,\n",
       "            0.00000000e+000,  6.05273523e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 7.21389319e-001,  0.00000000e+000,  8.32389858e-001,\n",
       "            0.00000000e+000, -7.01374686e-001]]],\n",
       "\n",
       "\n",
       "        [[[-1.84024502e+000,  0.00000000e+000,  6.80106399e-001,\n",
       "            0.00000000e+000,  9.81991203e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.54305373e-001,  0.00000000e+000, -1.21310590e+000,\n",
       "            0.00000000e+000,  1.43990030e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.41487628e+000,  0.00000000e+000, -1.61291038e+000,\n",
       "            0.00000000e+000, -4.91615683e-002]],\n",
       "\n",
       "         [[-1.84024502e+000,  0.00000000e+000,  6.80106399e-001,\n",
       "            0.00000000e+000,  9.81991203e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.54305373e-001,  0.00000000e+000, -1.21310590e+000,\n",
       "            0.00000000e+000,  1.43990030e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.41487628e+000,  0.00000000e+000, -1.61291038e+000,\n",
       "            0.00000000e+000, -4.91615683e-002]],\n",
       "\n",
       "         [[-1.84024502e+000,  0.00000000e+000,  6.80106399e-001,\n",
       "            0.00000000e+000,  9.81991203e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.54305373e-001,  0.00000000e+000, -1.21310590e+000,\n",
       "            0.00000000e+000,  1.43990030e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 1.41487628e+000,  0.00000000e+000, -1.61291038e+000,\n",
       "            0.00000000e+000, -4.91615683e-002]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[-1.10517074e+000,  0.00000000e+000,  7.92578605e-001,\n",
       "            0.00000000e+000, -4.05727201e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 2.86583959e-001,  0.00000000e+000,  8.29366310e-001,\n",
       "            0.00000000e+000, -5.96038304e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.05664468e+000,  0.00000000e+000, -2.50846281e-001,\n",
       "            0.00000000e+000, -5.61127534e-001]],\n",
       "\n",
       "         [[-1.10517074e+000,  0.00000000e+000,  7.92578605e-001,\n",
       "            0.00000000e+000, -4.05727201e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 2.86583959e-001,  0.00000000e+000,  8.29366310e-001,\n",
       "            0.00000000e+000, -5.96038304e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.05664468e+000,  0.00000000e+000, -2.50846281e-001,\n",
       "            0.00000000e+000, -5.61127534e-001]],\n",
       "\n",
       "         [[-1.10517074e+000,  0.00000000e+000,  7.92578605e-001,\n",
       "            0.00000000e+000, -4.05727201e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 2.86583959e-001,  0.00000000e+000,  8.29366310e-001,\n",
       "            0.00000000e+000, -5.96038304e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.05664468e+000,  0.00000000e+000, -2.50846281e-001,\n",
       "            0.00000000e+000, -5.61127534e-001]]],\n",
       "\n",
       "\n",
       "        [[[-9.63588868e-001,  0.00000000e+000, -8.93250691e-002,\n",
       "            0.00000000e+000,  6.86608087e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-3.04151405e-002,  0.00000000e+000,  1.62181429e+000,\n",
       "            0.00000000e+000,  1.15910145e+000],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 2.40105779e-001,  0.00000000e+000,  1.32597791e+000,\n",
       "            0.00000000e+000,  1.39101094e-001]],\n",
       "\n",
       "         [[-9.63588868e-001,  0.00000000e+000, -8.93250691e-002,\n",
       "            0.00000000e+000,  6.86608087e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-3.04151405e-002,  0.00000000e+000,  1.62181429e+000,\n",
       "            0.00000000e+000,  1.15910145e+000],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 2.40105779e-001,  0.00000000e+000,  1.32597791e+000,\n",
       "            0.00000000e+000,  1.39101094e-001]],\n",
       "\n",
       "         [[-9.63588868e-001,  0.00000000e+000, -8.93250691e-002,\n",
       "            0.00000000e+000,  6.86608087e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-3.04151405e-002,  0.00000000e+000,  1.62181429e+000,\n",
       "            0.00000000e+000,  1.15910145e+000],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [ 2.40105779e-001,  0.00000000e+000,  1.32597791e+000,\n",
       "            0.00000000e+000,  1.39101094e-001]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[-9.45994353e-001,  0.00000000e+000, -5.44660466e-001,\n",
       "            0.00000000e+000, -3.65070111e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.34193343e+000,  0.00000000e+000,  8.08511693e-001,\n",
       "            0.00000000e+000,  4.68190004e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.74775654e-001,  0.00000000e+000,  3.49389156e-002,\n",
       "            0.00000000e+000,  2.27314864e-001]],\n",
       "\n",
       "         [[-9.45994353e-001,  0.00000000e+000, -5.44660466e-001,\n",
       "            0.00000000e+000, -3.65070111e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.34193343e+000,  0.00000000e+000,  8.08511693e-001,\n",
       "            0.00000000e+000,  4.68190004e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.74775654e-001,  0.00000000e+000,  3.49389156e-002,\n",
       "            0.00000000e+000,  2.27314864e-001]],\n",
       "\n",
       "         [[-9.45994353e-001,  0.00000000e+000, -5.44660466e-001,\n",
       "            0.00000000e+000, -3.65070111e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-1.34193343e+000,  0.00000000e+000,  8.08511693e-001,\n",
       "            0.00000000e+000,  4.68190004e-001],\n",
       "          [ 0.00000000e+000,  0.00000000e+000,  0.00000000e+000,\n",
       "            0.00000000e+000,  0.00000000e+000],\n",
       "          [-9.74775654e-001,  0.00000000e+000,  3.49389156e-002,\n",
       "            0.00000000e+000,  2.27314864e-001]]],\n",
       "\n",
       "\n",
       "        [[[ 0.00000000e+000,  3.22542266e-307,  9.74301210e-312,\n",
       "            9.74312320e-312,  4.94065646e-324],\n",
       "          [ 6.95295141e-310,  8.69555537e-322,  9.74324548e-312,\n",
       "            9.74324451e-312,  9.74313432e-312],\n",
       "          [ 9.74324360e-312,  9.74313613e-312,  9.74324434e-312,\n",
       "            9.74324434e-312,  9.74324432e-312],\n",
       "          [ 9.74324433e-312,  9.74324433e-312,  9.74324433e-312,\n",
       "            9.74324434e-312,  9.74324433e-312],\n",
       "          [ 9.74324433e-312,  9.74313712e-312,  9.74314435e-312,\n",
       "            9.74314433e-312,  9.74314434e-312]],\n",
       "\n",
       "         [[ 0.00000000e+000,  3.22542266e-307,  9.74301210e-312,\n",
       "            9.74312320e-312,  4.94065646e-324],\n",
       "          [ 6.95295141e-310,  8.69555537e-322,  9.74324548e-312,\n",
       "            9.74324451e-312,  9.74313432e-312],\n",
       "          [ 9.74324360e-312,  9.74313613e-312,  9.74324434e-312,\n",
       "            9.74324434e-312,  9.74324432e-312],\n",
       "          [ 9.74324433e-312,  9.74324433e-312,  9.74324433e-312,\n",
       "            9.74324434e-312,  9.74324433e-312],\n",
       "          [ 9.74324433e-312,  9.74313712e-312,  9.74314435e-312,\n",
       "            9.74314433e-312,  9.74314434e-312]],\n",
       "\n",
       "         [[ 0.00000000e+000,  3.22542266e-307,  9.74301210e-312,\n",
       "            9.74312320e-312,  4.94065646e-324],\n",
       "          [ 6.95295141e-310,  8.69555537e-322,  9.74324548e-312,\n",
       "            9.74324451e-312,  9.74313432e-312],\n",
       "          [ 9.74324360e-312,  9.74313613e-312,  9.74324434e-312,\n",
       "            9.74324434e-312,  9.74324432e-312],\n",
       "          [ 9.74324433e-312,  9.74324433e-312,  9.74324433e-312,\n",
       "            9.74324434e-312,  9.74324433e-312],\n",
       "          [ 9.74324433e-312,  9.74313712e-312,  9.74314435e-312,\n",
       "            9.74314433e-312,  9.74314434e-312]]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing for backprop code\n",
    "strided_error = np.random.normal(size=(2, 3, 3, 3))\n",
    "stride = 2\n",
    "curr_error = strided_error\n",
    "\n",
    "num_images, num_filters, rows, cols = strided_error.shape\n",
    "new_dim = cols + (cols - 1) * (stride - 1)\n",
    "\n",
    "# array with new dimensions (same number of rows and cols)\n",
    "err = np.zeros(shape=(num_images, num_filters, new_dim, new_dim))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        err[:, :, [i * stride], [j * stride]] = curr_error[:, :, [i], [j]]\n",
    "\n",
    "strided_error = err\n",
    "                \n",
    "image_stride, channel_stride, row_stride, col_stride = strided_error.strides\n",
    "depth = 3\n",
    "strided_error = np.lib.stride_tricks.as_strided(strided_error,\n",
    "                                                shape=(4, 2, depth, new_dim, new_dim), \n",
    "                                                strides=(channel_stride, image_stride, 0, row_stride, col_stride))\n",
    "\n",
    "strided_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
